{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook is for scraping the data from pro-football-reference.com. It uses the requests_html package to fetch the html webpage and the html nodes on the page. Then, using pandas, a dataframe object is created and exported to a CSV file.\n",
    "\n",
    "**Note that running this will create 11 csv files in the ./Data/ directory; this will have a different effect based on the directory from which you run the jupyter notebook. In order to reproduce correctly, please run \"mkdir Data\" at the command line to create the directory that this script references.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft_2006.csv written\n",
      "Draft_2007.csv written\n",
      "Draft_2008.csv written\n",
      "Draft_2009.csv written\n",
      "Draft_2010.csv written\n",
      "Draft_2011.csv written\n",
      "Draft_2012.csv written\n",
      "Draft_2013.csv written\n",
      "Draft_2014.csv written\n",
      "Draft_2015.csv written\n",
      "Draft_2016.csv written\n"
     ]
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "session = HTMLSession()\n",
    "\n",
    "for year in range(2006, 2017):\n",
    "    url = \"https://www.pro-football-reference.com/years/\" + str(year) + \"/draft.htm\"\n",
    "    page = session.get(url)\n",
    "    rnd = []\n",
    "    pick = []\n",
    "    team = []\n",
    "    player = []\n",
    "    position = []\n",
    "    AV = []\n",
    "    AV_tm = []\n",
    "    GP = []\n",
    "    rd = page.html.find('#drafts th.right')\n",
    "    pk = page.html.find('#drafts td:nth-child(2)')\n",
    "    tm = page.html.find('#drafts td:nth-child(3)')\n",
    "    plr = page.html.find('#drafts td:nth-child(4)')\n",
    "    pos = page.html.find('#drafts td:nth-child(5)')\n",
    "    val = page.html.find('#drafts td:nth-child(11)')\n",
    "    val_tm = page.html.find('#drafts td:nth-child(12)')\n",
    "    gm = page.html.find('#drafts td:nth-child(13)')\n",
    "    for i in range(0, len(rd)):\n",
    "        rnd.append(rd[i].text)\n",
    "        pick.append(pk[i].text)\n",
    "        team.append(tm[i].text)\n",
    "        player.append(plr[i].text)\n",
    "        position.append(pos[i].text)\n",
    "        AV.append(val[i].text)\n",
    "        AV_tm.append(val_tm[i].text)\n",
    "        GP.append(gm[i].text)\n",
    "    ## Add exception handling for duplicate names, happens in 2012 draft with \"Robert Griffin\"\n",
    "    def list_duplicates(seq):\n",
    "        seen = set()\n",
    "        seen_add = seen.add\n",
    "        return [idx for idx,item in enumerate(seq) if item in seen or seen_add(item)]\n",
    "    if len(player) != len(set(player)):\n",
    "        duplicate_name_indices = list_duplicates(player)\n",
    "        player[duplicate_name_indices[0]] = player[duplicate_name_indices[0]] + \" 2\"\n",
    "    draft_df = pd.DataFrame(np.column_stack([rnd, pick, team, player, position, AV, AV_tm, GP]), \n",
    "                            columns=['Round', 'Pick', 'Team', 'Player', 'Position', 'AV', 'AV_Team', 'GP'])\n",
    "    filename = \"Draft_\" + str(year) + \".csv\"\n",
    "    draft_df.to_csv((\"./Data/\" + filename), index = False)\n",
    "    print(filename + \" written.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
